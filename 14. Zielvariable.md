### 68. Welchen Einfluss können nicht balancierte Trainingsdaten auf Ergebnisse maschinellen Lernen unter ethischen Gesichtspunkten haben?
- Wenn bestimmte Gruppen (z.B. ethnische Minderheiten oder Geschlechter) im Trainingsdatensatz **unterrepräsentiert** sind, kann das Modell systematisch schlechtere Ergebnisse für diese Gruppen liefern, was zu **Diskriminierung** führen kann.

### 69. Nennen Sie mindestens drei Verfahren zur Balancierung einer Zielvariablen
- Oversampling der Minderheitsklasse
- Undersampling der Mehrheitsklasse
- k-NN Verfahren (bei Balancierung nach euklidischem Abstand)

### 70. Welchen Vorteil hat das SMOTE Verfahren gegenüber der einfachen Vervielfachung von Datensätzen der Minderheitsklasse beim Random Oversampling?
- Varianz wird weniger verringert, da völlig neue Punkte dazukommen
![[Pasted image 20240916173944.png]]


### 71. Welchen Vorteil hat das Verfahren der Tomek Links gegenüber der einfachen Reduktion von Datensätzen der Mehrheitsklasse beim Random Oversampling?
- Trennbarkeit der Klassen wird verbessert -> Grenzfälle zwischen Klassen werden identifiziert
- Wichtige Informationen bleiben erhalten, nur die an der Grenze werden entfernt
- Bei einfachem Random Undersampling besteht die Gefahr, dass **wichtige Datenpunkte** verloren gehen, die für eine gute Klassifizierung entscheidend sind
 ![[Pasted image 20240916174201.png]]

### 72. Wie können Sie bei random over sampling eine sehr kleine Präzision in Bezug auf falsch postive Vorhersagen einer binären Klassifikation erklären?
- Da das Modell aufgrund des Oversamplings **mehr Beispiele der Minderheitsklasse** sieht, wird es **überoptimistisch** in der Klassifizierung dieser Klasse. Das Modell neigt dazu, mehr Fälle als **positiv** (Minderheitsklasse) zu klassifizieren, auch wenn sie in Wirklichkeit zur **Mehrheitsklasse** gehören.